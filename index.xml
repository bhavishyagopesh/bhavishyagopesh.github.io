<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Non-trivial Pursuit! on Non-trivial Pursuit!</title>
    <link>https://bhavishyagopesh.github.io/</link>
    <description>Recent content in Non-trivial Pursuit! on Non-trivial Pursuit!</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0530</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>On the Size of XORs and Randomization in Approximate Model Counters</title>
      <link>https://bhavishyagopesh.github.io/post/tacas2019/</link>
      <pubDate>Sun, 16 Dec 2018 00:00:00 +0530</pubDate>
      
      <guid>https://bhavishyagopesh.github.io/post/tacas2019/</guid>
      <description>

&lt;p&gt;Note:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;This post is based on our&lt;/em&gt; (&lt;a href=&#34;http://www.comp.nus.edu.sg/~meel/&#34; target=&#34;_blank&#34;&gt;Kuldeep&lt;/a&gt; and &lt;a href=&#34;http://bhavishyagopesh.github.io&#34; target=&#34;_blank&#34;&gt;yours truly&lt;/a&gt; )  &lt;em&gt;paper submitted in&lt;/em&gt; &lt;a href=&#34;https://www.etaps.org/2019/tacas&#34; target=&#34;_blank&#34;&gt;TACAS2019&lt;/a&gt; &lt;em&gt;and is currently a work in progress.&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Currently some of the repositories might not be publicly available.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;prelude-what-is-approximate-model-counting-sup-1-fn1-sup&#34;&gt;Prelude: What is (approximate) Model Counting?&lt;sup&gt;&lt;a href=&#34;#fn1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/h2&gt;

&lt;hr /&gt;

&lt;p&gt;Given a Boolean formula, say $ \phi $, to to compute the number of solutions of $ \phi $
is called (Exact) Model Counting. But it turns out it&amp;rsquo;s &lt;strong&gt;NP-hard&lt;/strong&gt; ( Actual it&amp;rsquo;s #P, which is a class of counting problems associated with decision problems, and therefore is harder than NP-complete problems because counting the solutions is definitely harder than identifying one ).&lt;/p&gt;

&lt;p&gt;So theoretically we can’t even approximate a solution in general, but it turns out
we can still approximate reasonable sized( with over 1000 variables) problems with present day &lt;a href=&#34;https://github.com/msoos/cryptominisat&#34; target=&#34;_blank&#34;&gt;SAT
solvers&lt;/a&gt;, hence the name Approximate Model Counting.&lt;/p&gt;

&lt;p&gt;The basic idea is this: Suppose you were to calculate the number of people in a large room. How would you do it  as efficiently as possible. One obvious way is to simply count each person but that&amp;rsquo;s too costly ( $O(n)$ where $n$ is exponentially large  ), it turns out there is a clever way to count by exploiting randomness( ask each person to get a coin ). Consider the following algorithm,&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Every person starts with a hand up.

Everyone tosses a coin
If it&#39;s a head, keep your hand up
Else bring it down 
Repeat till all hands are down.

Report  2^(number_of_rounds)  as the estimate.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Observe that the above algorithm takes $O(\log(n))$ steps in expectation and returns the correct count with a high probability.&lt;/p&gt;

&lt;p&gt;Now in practice this is achievedi(with some extra details) using a powerful mathematical tool called &lt;a href=&#34;https://www.wikiwand.com/en/Universal_hashing&#34; target=&#34;_blank&#34;&gt;2-Univerasal Hash Family&lt;/a&gt; , which is very good at dividing the solution space in small cells( each with a small number of elements), and a SAT solver which can (somewhat majically) count the number of cells with elements greater than some number (called the &lt;strong&gt;pivot&lt;/strong&gt;, we usually set it to 72 ).&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;span style=&#34;color:yellow&#34;&gt; Now &lt;strong&gt;pivot&lt;/strong&gt; $\times$ #number_of_cells gives the approximate count.&lt;/span&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://bhavishyagopesh.github.io/post/approxcount.jpeg&#34; alt=&#34;ApproxCount&#34; /&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;Approximate Counting&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;a-word-on-xors&#34;&gt;A word on XORs&lt;/h2&gt;

&lt;hr /&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://bhavishyagopesh.github.io/post/xors.jpeg&#34; alt=&#34;XOR function&#34; /&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;XOR function&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Now hash function is actually implemented by adding XORs with density  $p=\frac{1}{2}$.
 Thus on average XOR constraint size is $n/2$ where $n$ is number of variables.&lt;/p&gt;

&lt;p&gt;Constraints with smaller size are  friendlier to SAT solvers hence &lt;a href=&#34;https://arxiv.org/pdf/1512.08863.pdf&#34; target=&#34;_blank&#34;&gt;Zhao et al&lt;/a&gt; proposed a family of sparse hash functions with $p\le1/2$ (actually $\log(n)/n$ asymptotically)) to decrease the size of XOR constraints and hence make it easy for the SAT solver and
hence decreasing the runtime of counter( they proposed an algorithm &lt;em&gt;SparseCount&lt;/em&gt;, you can check out our implementation &lt;a href=&#34;https://github.com/meelgroup/SparseCount&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; ).&lt;/p&gt;

&lt;p&gt;But it turns out if we use sparse families then we loose the gurantees
on the count. So to achieve the same guarantees we end up increasing the number of iterations (by a factor $&amp;gt;100$ ) and thereby the runtime.&lt;/p&gt;

&lt;p&gt;After seeing &lt;a href=&#34;https://arxiv.org/pdf/1512.08863.pdf&#34; target=&#34;_blank&#34;&gt;Zhao et al&lt;/a&gt; paper we did some  calculations and ran some simulations suggesting that sparse-XORs won&amp;rsquo;t work in practice. In the next section we describe major results from the paper.&lt;/p&gt;

&lt;p&gt;Other popular belief in SAT community was that sparse constraints could be used directly with &lt;a href=&#34;https://github.com/meelgroup/APproxMC&#34; target=&#34;_blank&#34;&gt;ApproxMC&lt;/a&gt;. We show that&amp;rsquo;s not the case atleast from the analysis of  &lt;a href=&#34;https://arxiv.org/pdf/1512.08863.pdf&#34; target=&#34;_blank&#34;&gt;Zhao et al&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;major-results&#34;&gt;Major Results&lt;/h2&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;1-spaesecount2-a-better-version-of-sparsecount-based-on-prefix-slicing&#34;&gt;1.) Spaesecount2:  A better version of Sparsecount based on &lt;em&gt;prefix-slicing&lt;/em&gt;&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;Prefix-slicing is a technique that uses prefixes of previous hash functions, thereby making them dependent.
This dependence creates a ordering which could to perform Galloping Search( similar to Binary Search).
Thus reducing the number of SAT oracle calls from linear to logarithmic.
  &lt;p style=&#34;text-align: center;&#34;&gt;   $ n \rightarrow \log(n)$ &lt;/p&gt;
  &lt;br&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This was the idea that made &lt;a href=&#34;https://www.comp.nus.edu.sg/~meel/Papers/ijcai16_counting.pdf&#34; target=&#34;_blank&#34;&gt;ApproxMC3 much faster than ApproxMC&lt;/a&gt;. We applied to
  SparseCount and obtained significant speedups(&amp;gt; 2.5x).&lt;/p&gt;

&lt;p&gt;Code:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/meelgroup/Sparsecount2/releases&#34; target=&#34;_blank&#34;&gt;Release&lt;/a&gt;: Contains a prebuilt static binary&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/meelgroup/Sparsecount2/&#34; target=&#34;_blank&#34;&gt;Github Repo&lt;/a&gt;: Contains the SourceCode&lt;/p&gt;

&lt;h3 id=&#34;2-argument-for-why-sparse-xors-cannot-be-used-with-approxmc&#34;&gt;2.)  Argument for why sparse XORs cannot be used with ApproxMC&lt;/h3&gt;

&lt;p&gt;It turns out the properties of sparse hash families proposed by Zhao et al are  not sufficient for
proofs of ApproxMC3 to go through. The proofs of ApproxMC3 depend on the relationship between variance($\sigma^{2}$)
 and mean($\mu$), specifically for proofs to work out $\sigma^{2} \leq \mu^{2}$.
 But with proposed family  of hash functions
it could be shown that $ \sigma^{2} \leq \eta $ where $\eta$ $\in$  $\Omega(\mu^{2})$.&lt;/p&gt;

&lt;h3 id=&#34;3-empirical-results-supporting-our-arguments&#34;&gt;3.) Empirical results supporting our arguments&lt;/h3&gt;

&lt;p&gt;All four algorithms, &lt;a href=&#34;https://github.com/meelgroup/Sparsecount/releases&#34; target=&#34;_blank&#34;&gt;SparseCount&lt;/a&gt;, &lt;a href=&#34;https://github.com/meelgroup/Sparsecount2/releases&#34; target=&#34;_blank&#34;&gt;SparseCount2&lt;/a&gt;,  &lt;a href=&#34;https://github.com/meelgroup/ApproxMC/releases&#34; target=&#34;_blank&#34;&gt;ApproxMC&lt;/a&gt;, and &lt;a href=&#34;https://github.com/meelgroup/Toeplitz-ApproxMC/releases&#34; target=&#34;_blank&#34;&gt;Toeplitz-ApproxMC&lt;/a&gt;
implemented in C++ and use the same underlying SAT solver,
&lt;a href=&#34;https://github.com/msoos/cryptominisat&#34; target=&#34;_blank&#34;&gt;CryptoMiniSAT&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Our algorithm SparseCount2 is 2.5x faster than Zhao et’al’s
SparseCount.&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://bhavishyagopesh.github.io/post/msc.png&#34; alt=&#34;SparseCount vis-a-vis SparseCount2&#34; /&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;SparseCount vis-a-vis SparseCount2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Also the usual ApproxMC3 (with p = &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;) is 118x faster than
SparseCount.&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://bhavishyagopesh.github.io/post/triple_sparse_vs_scalmc.png&#34; alt=&#34;ApproxMC3 vis-a-vis SparseCount2&#34; /&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;ApproxMC3 vis-a-vis SparseCount2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;effect-of-randomness&#34;&gt;Effect of Randomness&lt;/h3&gt;

&lt;p&gt;It was proposed by &lt;a href=&#34;https://cs.stanford.edu/~ermon/papers/SparseHashing-revised.pdf&#34; target=&#34;_blank&#34;&gt;Ermon et al&lt;/a&gt;
that usage of &lt;a href=&#34;https://en.wikipedia.org/wiki/Toeplitz_matrix&#34; target=&#34;_blank&#34;&gt;Toeplitz matrix&lt;/a&gt; where all the entries are not independent leads to more
deterministic and stable behavior in their hashing-based algorithm for approximate
weighted model counting, also known as discrete integration. We tried an implementation based on Toeplitz matrix to see if it has any effect.
Note that usage of
Toeplitz matrices bring down requirement of random bits from $O(mn)$ to $O(m+n)$.&lt;/p&gt;

&lt;h2 id=&#34;we-observe-that-there-is-no-visible-effect&#34;&gt;&lt;strong&gt;We observe that there is no visible effect.&lt;/strong&gt;&lt;/h2&gt;

&lt;hr /&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;img src=&#34;https://bhavishyagopesh.github.io/post/teoplitz-scalmc.png&#34; alt=&#34;ApproxMC3 vs Toeplitz-ApproxMC3 comparison&#34; /&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;ApproxMC3 vs Toeplitz-ApproxMC3 comparison&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h2&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Hashing-based techniques have emerged as a promising paradigm to
attain scalability and rigorous guarantees in the context of
approximate model counting.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The core idea of a hashing-based framework is a combination of SAT
solving and usage of random XOR constraints to partition the
solution space.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Since the performance of SAT solvers was observed to degrade with
increase in the size of XORs, efforts have focused on the design of
sparse hash functions .&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Our conclusions are surprising and stand in stark contrast to widely
believed beliefs that current construction of sparse XORs (by Zhao et
al. and Ermon et al. ) lead to runtime improvement specifically we observe that&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Sparse constraints do not work with ApproxMC3.&lt;/li&gt;
&lt;li&gt;Sparsecount2 performs better than SparseCount&lt;/li&gt;
&lt;li&gt;ApproxMC3 performs much better than both SparseCount and Spaesecount2&lt;/li&gt;
&lt;li&gt;Toeplitz matrices have no effect on run-time&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;a name=&#34;fn1&#34;&gt; [1] &lt;/a&gt; You can find a nice blogpost , with much more SAT solver internal details, on the same &lt;a href=&#34;https://www.msoos.org/2018/12/how-approximate-model-counting-works/&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On minimal degree of Summetric Boolean Functions</title>
      <link>https://bhavishyagopesh.github.io/post/symmetric_boolean_functions/</link>
      <pubDate>Wed, 12 Dec 2018 00:00:00 +0530</pubDate>
      
      <guid>https://bhavishyagopesh.github.io/post/symmetric_boolean_functions/</guid>
      <description>&lt;p&gt;Very rough &lt;a href=&#34;https://bhavishyagopesh.github.io/post/notes.pdf&#34;&gt;notes&lt;/a&gt; on the topic, mostly based on the following papers,&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; * [Gill Cohen&#39;s MS thesis](http://www.cs.technion.ac.il/users/wwwb/cgi-bin/tr-get.cgi/2010/MSC/MSC-2010-13.pdf)

 * [VON ZUR GATHEN and Roche](https://link.springer.com/content/pdf/10.1007%2FBF01215917.pdf)

 * [Noam Nisan and  MARIO SZEGEDY ](https://link.springer.com/content/pdf/10.1007%2FBF01263419.pdf)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Effect of SparseXORs on Model Counting</title>
      <link>https://bhavishyagopesh.github.io/talk/ugp1/</link>
      <pubDate>Mon, 26 Nov 2018 00:00:00 +0530</pubDate>
      
      <guid>https://bhavishyagopesh.github.io/talk/ugp1/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
